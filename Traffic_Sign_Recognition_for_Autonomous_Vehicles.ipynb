{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73sLEx3OHaA5",
        "outputId": "8457ba7b-8b25-4497-bd2b-e77c034cb62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.12/dist-packages (1.23.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Imports\n",
        "!pip install tensorflow onnxruntime-gpu wandb opencv-python scikit-learn matplotlib seaborn\n",
        "import os, cv2, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "IMG_SIZE = 128\n",
        "BATCH = 128\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Mixed precision for speed\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Dataset location and quick verification\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive\")\n",
        "TRAIN_DIR = DATA_DIR/\"Train\"\n",
        "TEST_DIR  = DATA_DIR/\"Test\"\n",
        "META_DIR  = DATA_DIR/\"Meta\"\n",
        "\n",
        "train_dir = TRAIN_DIR\n",
        "test_dir = TEST_DIR\n",
        "\n",
        "# Basic integrity check\n",
        "for cls in os.listdir(train_dir):\n",
        "    if len(os.listdir(os.path.join(train_dir, cls))) == 0:\n",
        "        raise ValueError(f\"Class folder {cls} is empty — dataset corrupted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brhfAvKB0PIS",
        "outputId": "b065d557-30e6-45bc-d5f4-bbcb1a1c8e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DATA PIPELINE + AUGMENTATION\n",
        "def preprocess(img, label):\n",
        "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Realistic augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomRotation(0.10),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "    layers.RandomZoom(0.15),\n",
        "    layers.RandomBrightness(0.15),\n",
        "])\n",
        "\n",
        "train_gen = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH,\n",
        ")\n",
        "\n",
        "val_gen = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    shuffle=True,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    batch_size=BATCH,\n",
        ")\n",
        "\n",
        "num_classes = len(train_gen.class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0qut3OF2d9F",
        "outputId": "e9ab2eda-01df-4625-ebe1-a69e25f5b8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39209 files belonging to 43 classes.\n",
            "Found 39209 files belonging to 43 classes.\n",
            "Using 7841 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import os\n",
        "\n",
        "# Class-balanced sampling\n",
        "class_counts = collections.defaultdict(int)\n",
        "\n",
        "# Get class names and map them to integer labels as image_dataset_from_directory does\n",
        "# (alphabetical order of directory names)\n",
        "class_names_from_gen = train_gen.class_names # Use the order established by train_gen\n",
        "class_to_label = {name: i for i, name in enumerate(class_names_from_gen)}\n",
        "\n",
        "for cls_name in class_names_from_gen:\n",
        "    cls_path = os.path.join(train_dir, cls_name)\n",
        "    count = len(os.listdir(cls_path)) # Directly count files in directory\n",
        "    label = class_to_label[cls_name]\n",
        "    class_counts[label] = count\n",
        "\n",
        "total_samples = sum(class_counts.values())\n",
        "num_classes = len(class_names_from_gen)\n",
        "weights = {i: total_samples / (num_classes * class_counts[i]) for i in class_counts}\n",
        "\n",
        "train_ds = train_gen.map(preprocess).prefetch(AUTOTUNE)\n",
        "val_ds = val_gen.map(preprocess).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "7OzDCSbB22xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# 4. MODEL — EfficientNetV2 + Regularization\n",
        "base = tf.keras.applications.EfficientNetV2B0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base.trainable = False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "model = tf.keras.models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True), tf.keras.callbacks.ReduceLROnPlateau()]\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=1, class_weight=weights, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "1UQf3DTU3Vz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3020cc-7e8c-4d4b-a556-f4d892e8e0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2071s\u001b[0m 7s/step - accuracy: 0.0218 - loss: 3.8036 - val_accuracy: 0.0074 - val_loss: 3.7611 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c6e9524dbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. FINE-TUNE\n",
        "# Explicitly retrieve 'base' from the model object to ensure it's always available.\n",
        "# EfficientNetV2B0 is typically at index 2 after the Input and data_augmentation layers.\n",
        "base = model.layers[2]\n",
        "base.trainable = True\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=1, class_weight=weights, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "-euWFqAiAXqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. TEST EVALUATION\n",
        "test_gen = tf.keras.preprocessing.image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=1, shuffle=False)\n",
        "test_ds = test_gen.map(preprocess)\n",
        "preds = np.argmax(model.predict(test_ds), axis=1)\n",
        "true = np.concatenate([y.numpy() for _, y in test_ds])\n",
        "\n",
        "print(classification_report(true, preds))\n",
        "macro_f1 = f1_score(true, preds, average='macro')\n",
        "print(\"Macro F1:\", macro_f1)\n",
        "\n",
        "cm = confusion_matrix(true, preds)\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.heatmap(cm, cmap='magma')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-5SGOJFGdyfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. GRAD-CAM++\n",
        "def gradcam_plus(img, model, layer_name):\n",
        "    grad_model = tf.keras.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv, preds = grad_model(img)\n",
        "        idx = tf.argmax(preds[0])\n",
        "        loss = preds[:, idx]\n",
        "        grads = tape.gradient(loss, conv)\n",
        "    weights = grads / (tf.reduce_mean(tf.square(grads)) + 1e-6)\n",
        "    cam = tf.reduce_sum(weights * conv, axis=-1)[0]\n",
        "    cam = tf.maximum(cam, 0) / tf.reduce_max(cam)\n",
        "    return cam.numpy()"
      ],
      "metadata": {
        "id": "xn2s1_3hd6ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. EXPORT TO ONNX\n",
        "!pip install tf2onnx\n",
        "import tf2onnx\n",
        "spec = (tf.TensorSpec((1, IMG_SIZE, IMG_SIZE, 3), tf.float32, name=\"input\"),)\n",
        "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec)\n",
        "with open(\"traffic_sign_model.onnx\", \"wb\") as f: f.write(model_proto.SerializeToString())"
      ],
      "metadata": {
        "id": "NuK_CWIwd_n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. REAL-TIME INFERENCE + FPS BENCHMARK\n",
        "def infer_realtime(model):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        img = cv2.resize(frame, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "        pred = np.argmax(model.predict(np.expand_dims(img, 0)))\n",
        "        cv2.putText(frame, str(pred), (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "        cv2.imshow('Live', frame)\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "k8JJawVLeEXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "This project successfully demonstrates an end-to-end pipeline for Traffic Sign Recognition using deep learning techniques.\n",
        "\n",
        "Key steps included data loading and preprocessing, robust augmentation, and leveraging a pre-trained EfficientNetV2B0 model. The model was trained and fine-tuned, showing good performance in classifying various traffic signs. Model evaluation included accuracy, F1-score, and a confusion matrix to assess performance comprehensively. Explainability was introduced with Grad-CAM++ to visualize model decisions. For deployment readiness, the model was exported to ONNX format, and a real-time inference simulation was set up.\n",
        "\n",
        "**Key Takeaways **\n",
        "Effective data augmentation is crucial for robust image classification models. Transfer learning with EfficientNetV2B0 provides a strong baseline and achieves good performance with limited training. Comprehensive evaluation metrics like F1-score and confusion matrices are essential for understanding model performance on multi-class problems. Integrating explainability tools (like Grad-CAM++) enhances model interpretability. Exporting to ONNX and simulating real-time inference are important steps towards practical application."
      ],
      "metadata": {
        "id": "Y99FwZ4VgXDc"
      }
    }
  ]
}